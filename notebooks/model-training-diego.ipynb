{"cells":[{"cell_type":"markdown","metadata":{"id":"yAH0AL0cTFUa"},"source":["# Installation"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10354,"status":"ok","timestamp":1710514208507,"user":{"displayName":"Philipp Bosler","userId":"14784149596080531597"},"user_tz":180},"id":"BixTetstTE7u","outputId":"c01e0246-6e6a-4096-ab32-7f9f6435889b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.1/613.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q --upgrade keras-cv"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32607,"status":"ok","timestamp":1710514253426,"user":{"displayName":"Philipp Bosler","userId":"14784149596080531597"},"user_tz":180},"id":"9QdMAiIWl56t","outputId":"d1517a2b-c462-42b2-f5b5-17a789e3d8a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":254,"status":"ok","timestamp":1710514300232,"user":{"displayName":"Philipp Bosler","userId":"14784149596080531597"},"user_tz":180},"id":"mI-yTeczlxuV","outputId":"5f46e6b6-9a2b-47e0-db09-3cc8fbdb148a"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/NoLaTeX\n"]}],"source":["%cd /content/drive/MyDrive/Colab Notebooks/NoLaTeX"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":265,"status":"ok","timestamp":1710514311032,"user":{"displayName":"Philipp Bosler","userId":"14784149596080531597"},"user_tz":180},"id":"CVOe3MwamPxk","outputId":"95d9aa02-b430-47d6-9804-2ff8e932325c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/NoLaTeX\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nQCvHDHemTCe","outputId":"5001b795-0df1-41bc-b6b9-04379bbc1326"},"outputs":[{"name":"stdout","output_type":"stream","text":["Obtaining file:///content/drive/MyDrive/Colab%20Notebooks/NoLaTeX\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from nolatex==0.0.1) (7.4.4)\n","Collecting pylint (from nolatex==0.0.1)\n","  Downloading pylint-3.1.0-py3-none-any.whl (515 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.6/515.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ipdb (from nolatex==0.0.1)\n","  Downloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n","Collecting jupyterlab (from nolatex==0.0.1)\n","  Downloading jupyterlab-4.1.5-py3-none-any.whl (11.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nolatex==0.0.1) (1.25.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nolatex==0.0.1) (1.5.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from nolatex==0.0.1) (3.7.1)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from nolatex==0.0.1) (0.13.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nolatex==0.0.1) (1.2.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from nolatex==0.0.1) (4.8.0.76)\n","Requirement already satisfied: keras-cv in /usr/local/lib/python3.10/dist-packages (from nolatex==0.0.1) (0.8.2)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from nolatex==0.0.1) (0.19.3)\n","Collecting streamlit (from nolatex==0.0.1)\n","  Downloading streamlit-1.32.2-py2.py3-none-any.whl (8.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nolatex==0.0.1) (2.31.0)\n","Collecting tensorflow==2.10.0 (from nolatex==0.0.1)\n","  Downloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n","\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m557.1/578.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:10\u001b[0m"]}],"source":["!pip install -e ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Em3Prp_JZc0O"},"outputs":[],"source":["#uncoment to have time displayed on every cell\n","\n","# !pip install ipython-autotime\n","# %load_ext autotime"]},{"cell_type":"markdown","metadata":{"id":"_rJUdWYyTMAD"},"source":["# Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31696,"status":"ok","timestamp":1710379182195,"user":{"displayName":"Diego Beran","userId":"04658860050672428666"},"user_tz":180},"id":"rV343m6WQUTH","outputId":"890b61e2-e8f3-4bd7-d2d5-03577a5dd99c"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-03-15 16:40:39.532025: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-03-15 16:40:39.533321: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-03-15 16:40:39.543642: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-03-15 16:40:39.618273: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-03-15 16:40:41.115233: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/home/diegoberan/.pyenv/versions/3.10.6/envs/NoLaTeX/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["#import packages\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import math\n","#import tensorflow as tf\n","#import functions\n","from keras.utils import load_img\n","from keras.callbacks import ModelCheckpoint\n","from keras.optimizers import SGD\n","from keras.models import load_model\n","\n","from keras_cv import visualization\n","from keras_cv.layers import Resizing, NonMaxSuppression\n","from keras_cv.callbacks import PyCOCOCallback\n","from keras_cv.models import YOLOV8Detector\n","\n","from nolatex.ml_logic.utils import load_dataset"]},{"cell_type":"markdown","metadata":{"id":"IzaIQzfwRHHV"},"source":["# Define Paths"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"kW4AARMiQ2zw"},"outputs":[],"source":["json_path = \"/home/diegoberan/code/ChilleeX/NoLaTeX/initial_test_data/batch_1_sample5/kaggle_data_1.json\"\n","img_dir = \"/home/diegoberan/code/ChilleeX/NoLaTeX/initial_test_data/batch_1_sample5/images\""]},{"cell_type":"markdown","metadata":{"id":"qQJoMdNMltaq"},"source":["# Load Data into the right format"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"4454HYLNltas","outputId":"4da04f1a-e5a3-4d12-8b8e-84a55f9ee99c"},"outputs":[],"source":["dataset, class_mapping, low_contrast_imgs = load_dataset(img_dir=img_dir, json_path=json_path)\n","\n","num_classes = len(class_mapping)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["TensorShape([342, None, None])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["dataset[\"images\"][0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"THSuu919ltav"},"outputs":[],"source":["from sys import getsizeof\n","getsizeof(dataset)"]},{"cell_type":"markdown","metadata":{"id":"C-xfRosDltax"},"source":["# Image Resizing"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ub7g4uThSv5z"},"outputs":[],"source":["inference_resizing = Resizing(\n","    640, 640, pad_to_aspect_ratio=True, bounding_box_format=\"xywh\"\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Ycovl0HkTwMO"},"outputs":[],"source":["dataset_resized = inference_resizing(dataset)"]},{"cell_type":"markdown","metadata":{"id":"UpxP2KqFUD7S"},"source":["# Starting the model"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"YWVlWUAwVTfX"},"outputs":[],"source":["model_dir = \"\"\n","model_name = \"name\" + \".keras\"\n","model_path = os.path.join(model_dir, model_name)\n","\n","#Set model Params here\n","backbone_model = \"resnet50_imagenet\"\n","#Optimizer Params\n","base_lr = 0.005\n","momentum = 0.9\n","global_clipnorm = 10.0\n","#Loss Params\n","classification_loss = \"binary_crossentropy\"\n","box_loss = \"ciou\"\n","#Train Params\n","number_epochs = 1\n","batch_size = 32"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"c44Bo-fcUBJZ"},"outputs":[],"source":["model = YOLOV8Detector.from_preset(\n","    backbone_model,\n","    bounding_box_format=\"xywh\",\n","    num_classes=num_classes,\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ZYsQCqTFUH3k"},"outputs":[],"source":["# including a global_clipnorm is extremely important in object detection tasks\n","optimizer = SGD(\n","    learning_rate=base_lr, momentum=momentum, global_clipnorm=global_clipnorm\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"COa22ziVUXyA"},"outputs":[],"source":["model.compile(\n","    classification_loss=classification_loss,\n","    box_loss=box_loss,\n","    optimizer=optimizer,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QW7F416rVLw7"},"outputs":[],"source":["#Needs to be tested\n","# coco_metrics_callback = PyCOCOCallback(\n","#     resized_data, bounding_box_format=\"xywh\"\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aGJy5N3Qlta6"},"outputs":[],"source":["# Include the epoch in the file name (uses `str.format`)\n","checkpoint_path = os.path.join(model_dir, f\"{model_name}-cp-{epoch:04d}.ckpt\")\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","# Calculate the number of batches per epoch\n","n_batches = len(dataset['images']) / batch_size\n","n_batches = math.ceil(n_batches)    # round up the number of batches to the nearest whole integer\n","\n","# Create a callback that saves the model's weights every 5 epochs\n","cp_callback = ModelCheckpoint(\n","    filepath=checkpoint_path,\n","    verbose=1,\n","    save_weights_only=True,\n","    save_freq=\"epoch\"\n","    #save_freq=5*n_batches\n","    )\n","\n","# Save the weights using the `checkpoint_path` format\n","model.save_weights(checkpoint_path.format(epoch=0))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"D9Iy755WUawA"},"outputs":[{"ename":"ValueError","evalue":"Exception encountered when calling Functional.call().\n\n\u001b[1mInput 0 of layer \"conv1_conv\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 640, 640, 1)\u001b[0m\n\nArguments received by Functional.call():\n  • inputs=tf.Tensor(shape=(None, 640, 640, 1), dtype=float32)\n  • training=True\n  • mask=None","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#by just following the example notebook I managed to train 1 epoch in 45 minutes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#did not manage to run fit with 16 images, colab breaks when reaching around the 3 min mark\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_resized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Run for 10-35~ epochs to achieve good scores.\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumber_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#batch_size=batch_size,\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#callbacks=[cp_callback]\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#callbacks=[coco_metrics_callback]\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#model.save(model_path)\u001b[39;00m\n","File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/NoLaTeX/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/NoLaTeX/lib/python3.10/site-packages/keras_cv/src/models/object_detection/yolo_v8/yolo_v8_detector.py:526\u001b[0m, in \u001b[0;36mYOLOV8Detector.train_step\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    524\u001b[0m args \u001b[38;5;241m=\u001b[39m args[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    525\u001b[0m x, y \u001b[38;5;241m=\u001b[39m unpack_input(data)\n\u001b[0;32m--> 526\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Functional.call().\n\n\u001b[1mInput 0 of layer \"conv1_conv\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 640, 640, 1)\u001b[0m\n\nArguments received by Functional.call():\n  • inputs=tf.Tensor(shape=(None, 640, 640, 1), dtype=float32)\n  • training=True\n  • mask=None"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["#by just following the example notebook I managed to train 1 epoch in 45 minutes\n","#did not manage to run fit with 16 images, colab breaks when reaching around the 3 min mark\n","model.fit(\n","    dataset_resized,\n","    # Run for 10-35~ epochs to achieve good scores.\n","    epochs=number_epochs,\n","    #batch_size=batch_size,\n","    #callbacks=[cp_callback]\n","    #callbacks=[coco_metrics_callback]\n",")\n","\n","#model.save(model_path)"]},{"cell_type":"markdown","metadata":{"id":"e82I_aCjlta8"},"source":["# Loading Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zEZV4_pblta9"},"outputs":[],"source":["# Restore the weights\n","\n","#Important model needs to be initialized first\n","model.load_weights('./checkpoints/my_checkpoint')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R8OAkRc0lta-"},"outputs":[],"source":["# Loading a complete model\n","\n","new_model = load_model('my_model.keras')"]},{"cell_type":"markdown","metadata":{"id":"upJgHyM0UgCB"},"source":["# Ploting predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sV5QJOe_iNws"},"outputs":[],"source":["test_image_path = \"/content/drive/MyDrive/Pitch/test data/example_img.jpg\"\n","image_test = load_img(test_image_path)\n","image_test = np.array(image_test)\n","image_test_resized = inference_resizing([image_test])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f2tvCdHPUz7x"},"outputs":[],"source":["#Simple visualization (Already tested)\n","y_pred = model.predict(image_test_resized)\n","# y_pred is a bounding box Tensor:\n","# {\"classes\": ..., boxes\": ...}\n","visualization.plot_bounding_box_gallery(\n","    image_test_resized,\n","    value_range=(0, 255),\n","    rows=1,\n","    cols=1,\n","    y_pred=y_pred,\n","    scale=5,\n","    font_scale=0.7,\n","    bounding_box_format=\"xywh\",\n","    class_mapping=class_mapping,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dHsvVfTeW2JL"},"outputs":[],"source":["#Needs to be tested\n","model.prediction_decoder = NonMaxSuppression(\n","    bounding_box_format=\"xywh\",\n","    from_logits=True,\n","    iou_threshold=0.5,\n","    confidence_threshold=0.75,\n",")\n","visualize_detections(model, dataset=visualization_ds, bounding_box_format=\"xywh\")\n","\n","# visualization_ds on example notebook is en evaluation set\n","# visualization_ds = eval_ds.unbatch()\n","# visualization_ds = visualization_ds.ragged_batch(16)\n","# visualization_ds = visualization_ds.shuffle(8)"]},{"cell_type":"markdown","metadata":{"id":"YoH1P3y6XrCi"},"source":["#Experimental Stuff\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uZ2Xnym9Xtyj"},"outputs":[],"source":["class VisualizeDetections(keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs):\n","        visualize_detections(\n","            self.model, bounding_box_format=\"xywh\", dataset=visualization_ds\n","        )\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}
