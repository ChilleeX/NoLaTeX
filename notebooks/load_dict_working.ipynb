{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1B4L_P3ZJT14GmI0KtL24cC8OuR6SprL0","authorship_tag":"ABX9TyNqu3IYuHj5sqt0lzs3OQHI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Keras_cv instalation"],"metadata":{"id":"yAH0AL0cTFUa"}},{"cell_type":"code","source":["!pip install -q --upgrade keras-cv"],"metadata":{"id":"BixTetstTE7u","executionInfo":{"status":"ok","timestamp":1710379150503,"user_tz":180,"elapsed":10467,"user":{"displayName":"Diego Beran","userId":"04658860050672428666"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#uncoment to have time displayed on every cell\n","\n","# !pip install ipython-autotime\n","# %load_ext autotime"],"metadata":{"id":"Em3Prp_JZc0O","executionInfo":{"status":"ok","timestamp":1710379150504,"user_tz":180,"elapsed":6,"user":{"displayName":"Diego Beran","userId":"04658860050672428666"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["#Imports"],"metadata":{"id":"_rJUdWYyTMAD"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rV343m6WQUTH","executionInfo":{"status":"ok","timestamp":1710379182195,"user_tz":180,"elapsed":31696,"user":{"displayName":"Diego Beran","userId":"04658860050672428666"}},"outputId":"890b61e2-e8f3-4bd7-d2d5-03577a5dd99c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using TensorFlow backend\n"]}],"source":["#import packages\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import tensorflow as tf\n","#import functions\n","from keras.utils import load_img\n","from keras_cv.layers import Resizing, NonMaxSuppression\n","from keras.optimizers import SGD\n","from keras_cv import visualization\n","from keras_cv.callbacks import PyCOCOCallback\n","from keras_cv.models import YOLOV8Detector"]},{"cell_type":"markdown","source":["#Define Paths"],"metadata":{"id":"IzaIQzfwRHHV"}},{"cell_type":"code","source":["full_json_path = \"/content/drive/MyDrive/Pitch/batch_1/JSON/kaggle_data_1.json\"\n","img_folder_path = \"//content/drive/MyDrive/Pitch/batch_1/background_images_sample/images_16\""],"metadata":{"id":"kW4AARMiQ2zw","executionInfo":{"status":"ok","timestamp":1710379182196,"user_tz":180,"elapsed":15,"user":{"displayName":"Diego Beran","userId":"04658860050672428666"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["#Define Functions"],"metadata":{"id":"MbudbjR1RXIa"}},{"cell_type":"code","source":["def resample_json(img_path, full_json_path):\n","  \"\"\"takes a path to a folder of images and the path to the JSON file\n","  returns a dataframe with only the rows corresponding to the pictures in the file\"\"\"\n","  json = pd.read_json(full_json_path)\n","  dir_files = os.listdir(img_path)\n","  uuids = [file.replace('.jpg','') for file in dir_files]\n","  matches = json[\"uuid\"].isin(uuids)\n","  indices = np.where(matches)[0]\n","  index_list = indices.tolist()\n","  json_resampled = json[json.index.isin(index_list)]\n","  json_resampled.reset_index(drop=True, inplace=True)\n","  return json_resampled\n","\n","def load_to_dict(img_path, df):\n","  #Formating bounding boxes in XYWH format\n","  bboxs = []\n","  for img_pos in range(len(df['image_data'])):\n","    X = df['image_data'][img_pos]['xmins_raw']\n","    Y = df['image_data'][img_pos]['ymins_raw']\n","    W = np.array(df['image_data'][img_pos]['xmaxs_raw']) - np.array(df['image_data'][img_pos]['xmins_raw'])\n","    H = np.array(df['image_data'][img_pos]['ymaxs_raw']) - np.array(df['image_data'][img_pos]['ymins_raw'])\n","    bbox = [[X[i],Y[i],W[i],H[i]] for i in range(len(X))]\n","    bboxs.append(bbox)\n","  bboxs = tf.ragged.constant(bboxs)\n","  #loading images\n","  file_names = \"/\" + df[\"uuid\"] + \".jpg\"\n","  images = [np.array(load_img(img_path + file_name)) for file_name in file_names]\n","  images = tf.ragged.constant(images)\n","  #extracting classes\n","  classes = [df['image_data'][index]['visible_latex_chars'] for index in range(len(df['image_data']))]\n","  #Class_ids contais the unique classes\n","  class_ids = list(set([ele for sublist in classes for ele in sublist]))\n","  #mapping the classes\n","  mapping = {string: _ for _, string in enumerate(class_ids)}\n","  #converting the classes to numbers\n","  classes = [list(map(mapping.get, ele)) for ele in classes]\n","  classes = tf.ragged.constant(classes)\n","  #defining the right class mapping fo the model(inverse as mapping)\n","  class_mapping = dict(zip(range(len(class_ids)), class_ids))\n","\n","  #Loading things into the dict\n","  final_dict = {\"images\": images,\"bounding_boxes\":{\"classes\": classes , \"boxes\": bboxs}}\n","\n","  return final_dict, class_mapping\n","\n","#Visualisation function from example notebook\n","def visualize_detections(model, dataset, bounding_box_format):\n","  images, y_true = next(iter(dataset.take(1)))\n","  y_pred = model.predict(images)\n","  visualization.plot_bounding_box_gallery(\n","        images,\n","        value_range=(0, 255),\n","        bounding_box_format=bounding_box_format,\n","        y_true=y_true,\n","        y_pred=y_pred,\n","        scale=4,\n","        rows=2,\n","        cols=2,\n","        show=True,\n","        font_scale=0.7,\n","        class_mapping=class_mapping,\n","    )"],"metadata":{"id":"2tdgkzgMRZip","executionInfo":{"status":"ok","timestamp":1710379182197,"user_tz":180,"elapsed":15,"user":{"displayName":"Diego Beran","userId":"04658860050672428666"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["#Load Data into the right format"],"metadata":{"id":"tQ7Abgr1TSvK"}},{"cell_type":"code","source":["df = resample_json(img_folder_path, full_json_path)"],"metadata":{"id":"QHAYr-bZRx6N","executionInfo":{"status":"ok","timestamp":1710379194504,"user_tz":180,"elapsed":12322,"user":{"displayName":"Diego Beran","userId":"04658860050672428666"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["data, class_mapping = load_to_dict(img_folder_path, df)\n","#managed to load 16 images in 2 minutes, colab breaks every time I try 100 images"],"metadata":{"id":"b9aB6CPuSp4O","executionInfo":{"status":"ok","timestamp":1710379313483,"user_tz":180,"elapsed":118982,"user":{"displayName":"Diego Beran","userId":"04658860050672428666"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["inference_resizing = Resizing(\n","    640, 640, pad_to_aspect_ratio=True, bounding_box_format=\"xywh\"\n",")"],"metadata":{"id":"ub7g4uThSv5z","executionInfo":{"status":"ok","timestamp":1710379313483,"user_tz":180,"elapsed":4,"user":{"displayName":"Diego Beran","userId":"04658860050672428666"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["resized_data = inference_resizing(data)"],"metadata":{"id":"Ycovl0HkTwMO","executionInfo":{"status":"ok","timestamp":1710379321812,"user_tz":180,"elapsed":8331,"user":{"displayName":"Diego Beran","userId":"04658860050672428666"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["num_classes = len(class_mapping)"],"metadata":{"id":"izHduyP2T6oX","executionInfo":{"status":"ok","timestamp":1710379321812,"user_tz":180,"elapsed":6,"user":{"displayName":"Diego Beran","userId":"04658860050672428666"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["#Starting the model"],"metadata":{"id":"UpxP2KqFUD7S"}},{"cell_type":"code","source":["#Set model Params here\n","backbone_model = \"resnet50_imagenet\"\n","#Optimizer Params\n","base_lr = 0.005\n","momentum = 0.9\n","global_clipnorm = 10.0\n","#Loss Params\n","classification_loss = \"binary_crossentropy\"\n","box_loss = \"ciou\"\n","#Train Params\n","number_epochs = 1"],"metadata":{"id":"YWVlWUAwVTfX","executionInfo":{"status":"ok","timestamp":1710379321812,"user_tz":180,"elapsed":6,"user":{"displayName":"Diego Beran","userId":"04658860050672428666"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["model = YOLOV8Detector.from_preset(\n","    backbone_model,\n","    bounding_box_format=\"xywh\",\n","    num_classes=num_classes,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c44Bo-fcUBJZ","executionInfo":{"status":"ok","timestamp":1710379334466,"user_tz":180,"elapsed":12659,"user":{"displayName":"Diego Beran","userId":"04658860050672428666"}},"outputId":"66c49ba7-fb15-4a44-d856-3d7b4c9e1dce"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras_cv/src/models/backbones/backbone.py:44: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  return id(getattr(self, attr)) not in self._functional_layer_ids\n","/usr/local/lib/python3.10/dist-packages/keras_cv/src/models/backbones/backbone.py:44: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  return id(getattr(self, attr)) not in self._functional_layer_ids\n"]}]},{"cell_type":"code","source":["# including a global_clipnorm is extremely important in object detection tasks\n","optimizer = SGD(\n","    learning_rate=base_lr, momentum=momentum, global_clipnorm=global_clipnorm\n",")"],"metadata":{"id":"ZYsQCqTFUH3k","executionInfo":{"status":"ok","timestamp":1710379334467,"user_tz":180,"elapsed":13,"user":{"displayName":"Diego Beran","userId":"04658860050672428666"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["model.compile(\n","    classification_loss=classification_loss,\n","    box_loss=box_loss,\n","    optimizer=optimizer,\n",")"],"metadata":{"id":"COa22ziVUXyA","executionInfo":{"status":"ok","timestamp":1710379334467,"user_tz":180,"elapsed":12,"user":{"displayName":"Diego Beran","userId":"04658860050672428666"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["#Needs to be tested\n","# coco_metrics_callback = PyCOCOCallback(\n","#     resized_data, bounding_box_format=\"xywh\"\n","# )"],"metadata":{"id":"QW7F416rVLw7","executionInfo":{"status":"ok","timestamp":1710379334467,"user_tz":180,"elapsed":11,"user":{"displayName":"Diego Beran","userId":"04658860050672428666"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["#by just following the example notebook I managed to train 1 epoch in 45 minutes\n","#did not manage to run fit with 16 images, colab breaks when reaching around the 3 min mark\n","model.fit(\n","    resized_data,\n","    # Run for 10-35~ epochs to achieve good scores.\n","    epochs=number_epochs,\n","    #callbacks=[coco_metrics_callback]\n",")"],"metadata":{"id":"D9Iy755WUawA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Ploting predict"],"metadata":{"id":"upJgHyM0UgCB"}},{"cell_type":"code","source":["test_image_path = \"/content/drive/MyDrive/Pitch/test data/example_img.jpg\"\n","image_test = load_img(test_image_path)\n","image_test = np.array(image_test)\n","image_test_resized = inference_resizing([image_test])"],"metadata":{"id":"sV5QJOe_iNws"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Simple visualization (Already tested)\n","y_pred = model.predict(image_test_resized)\n","# y_pred is a bounding box Tensor:\n","# {\"classes\": ..., boxes\": ...}\n","visualization.plot_bounding_box_gallery(\n","    image_test_resized,\n","    value_range=(0, 255),\n","    rows=1,\n","    cols=1,\n","    y_pred=y_pred,\n","    scale=5,\n","    font_scale=0.7,\n","    bounding_box_format=\"xywh\",\n","    class_mapping=class_mapping,\n",")"],"metadata":{"id":"f2tvCdHPUz7x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Needs to be tested\n","model.prediction_decoder = NonMaxSuppression(\n","    bounding_box_format=\"xywh\",\n","    from_logits=True,\n","    iou_threshold=0.5,\n","    confidence_threshold=0.75,\n",")\n","visualize_detections(model, dataset=visualization_ds, bounding_box_format=\"xywh\")\n","\n","# visualization_ds on example notebook is en evaluation set\n","# visualization_ds = eval_ds.unbatch()\n","# visualization_ds = visualization_ds.ragged_batch(16)\n","# visualization_ds = visualization_ds.shuffle(8)"],"metadata":{"id":"dHsvVfTeW2JL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Experimental Stuff\n"],"metadata":{"id":"YoH1P3y6XrCi"}},{"cell_type":"code","source":["class VisualizeDetections(keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs):\n","        visualize_detections(\n","            self.model, bounding_box_format=\"xywh\", dataset=visualization_ds\n","        )\n"],"metadata":{"id":"uZ2Xnym9Xtyj"},"execution_count":null,"outputs":[]}]}